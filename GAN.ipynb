{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17GGqWOctIW09yadbV3asSg-aGjmj8kEn","timestamp":1737620029607}],"authorship_tag":"ABX9TyO3f55rRhIFbVgkDhBEN1m0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZud8uCXCD-6","executionInfo":{"status":"ok","timestamp":1737960279926,"user_tz":-330,"elapsed":24000,"user":{"displayName":"jayanth suresh","userId":"02580612912048283135"}},"outputId":"df0d45e0-81d6-45ab-fd93-244f0aba6549"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive')"],"metadata":{"id":"P_fkes6UIV5G","executionInfo":{"status":"ok","timestamp":1737960281851,"user_tz":-330,"elapsed":535,"user":{"displayName":"jayanth suresh","userId":"02580612912048283135"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"242hbTdsCB2s","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"error","timestamp":1737961345524,"user_tz":-330,"elapsed":1470,"user":{"displayName":"jayanth suresh","userId":"02580612912048283135"}},"outputId":"5e3dbc7b-a34a-4198-e13c-8db88750bd41"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"functional_17\" is incompatible with the layer: expected shape=(None, 512, 512, 3), found shape=(None, 256, 256, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • args=('<KerasTensor shape=(None, 256, 256, 3), dtype=float32, sparse=False, name=keras_tensor_326>',)\n  • kwargs={'mask': 'None'}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-983223d84a43>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-983223d84a43>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mdiscriminator_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-983223d84a43>\u001b[0m in \u001b[0;36mbuild_gan\u001b[0;34m(generator, discriminator)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mgan_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLATENT_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mgan_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    246\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"functional_17\" is incompatible with the layer: expected shape=(None, 512, 512, 3), found shape=(None, 256, 256, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • args=('<KerasTensor shape=(None, 256, 256, 3), dtype=float32, sparse=False, name=keras_tensor_326>',)\n  • kwargs={'mask': 'None'}"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","import os\n","import glob\n","import cv2\n","\n","# Set image size and latent dimension\n","IMAGE_SIZE = 512  # 512x512 images for real PAN cards\n","LATENT_DIM = 100  # Latent vector size\n","BATCH_SIZE = 32\n","EPOCHS = 10\n","\n","# Path to your dataset directory\n","dataset_dir = 'pre_processed_pan_cards/train/real'\n","\n","# Load images\n","def load_images(image_size=IMAGE_SIZE):\n","    images = []\n","    for img_path in glob.glob(os.path.join(dataset_dir, '*.jpg')):\n","        img = cv2.imread(img_path)\n","        img = cv2.resize(img, (image_size, image_size))  # Resize image\n","        images.append(img)\n","    images = np.array(images, dtype='float32')\n","    # Normalize images to [-1, 1]\n","    images = (images - 127.5) / 127.5\n","    return images\n","\n","# Load your dataset\n","dataset = load_images()\n","\n","# Build the Generator Model\n","def build_generator():\n","    model = tf.keras.Sequential([\n","        layers.Dense(4 * 4 * 1024, use_bias=False, input_shape=(LATENT_DIM,)),\n","        layers.BatchNormalization(),\n","        layers.LeakyReLU(),\n","\n","        layers.Reshape((4, 4, 1024)),\n","        layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","        layers.BatchNormalization(),\n","        layers.LeakyReLU(),\n","\n","        layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","        layers.BatchNormalization(),\n","        layers.LeakyReLU(),\n","\n","        layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","        layers.BatchNormalization(),\n","        layers.LeakyReLU(),\n","\n","        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","        layers.BatchNormalization(),\n","        layers.LeakyReLU(),\n","\n","        # Output layer with 512x512x3 (RGB channels)\n","        layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","        layers.BatchNormalization(),\n","        layers.LeakyReLU(),\n","\n","        # Ensure output size is 512x512x3 (RGB)\n","        layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')  # 512x512x3 output\n","    ])\n","    return model\n","\n","# Build the Discriminator Model\n","def build_discriminator():\n","    model = tf.keras.Sequential([\n","        layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n","        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Dropout(0.3),\n","\n","        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","        layers.BatchNormalization(),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Dropout(0.3),\n","\n","        layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","        layers.BatchNormalization(),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Dropout(0.3),\n","\n","        layers.Flatten(),\n","        layers.Dense(1)  # Output a single score (real or fake)\n","    ])\n","    return model\n","\n","# Define the GAN Model\n","def build_gan(generator, discriminator):\n","    discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    discriminator.trainable = False  # During GAN training, freeze the discriminator\n","\n","    gan_input = layers.Input(shape=(LATENT_DIM,))\n","    x = generator(gan_input)\n","    gan_output = discriminator(x)\n","\n","    gan = models.Model(gan_input, gan_output)\n","    gan.compile(optimizer='adam', loss='binary_crossentropy')\n","    return gan\n","\n","# Train step function\n","def train_step(real_images, latent_dim, generator, discriminator, gan):\n","    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))  # Generate random noise\n","    generated_images = generator(noise, training=True)\n","\n","    # Labels for real and fake images\n","    real_labels = np.ones((BATCH_SIZE, 1))\n","    fake_labels = np.zeros((BATCH_SIZE, 1))\n","\n","    # Train the discriminator\n","    with tf.GradientTape() as tape:\n","        real_output = discriminator(real_images, training=True)\n","        fake_output = discriminator(generated_images, training=True)\n","        real_loss = tf.keras.losses.binary_crossentropy(real_labels, real_output)\n","        fake_loss = tf.keras.losses.binary_crossentropy(fake_labels, fake_output)\n","        d_loss = real_loss + fake_loss\n","\n","    d_gradients = tape.gradient(d_loss, discriminator.trainable_variables)\n","    discriminator.optimizer.apply_gradients(zip(d_gradients, discriminator.trainable_variables))\n","\n","    # Train the generator via GAN model (discriminator is frozen)\n","    with tf.GradientTape() as tape:\n","        gan_loss = gan(noise, training=True)\n","\n","    g_gradients = tape.gradient(gan_loss, generator.trainable_variables)\n","    generator.optimizer.apply_gradients(zip(g_gradients, generator.trainable_variables))\n","\n","    return d_loss, gan_loss\n","\n","# Train the models\n","def train(dataset, epochs):\n","    generator = build_generator()\n","    discriminator = build_discriminator()\n","    gan = build_gan(generator, discriminator)\n","\n","    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n","    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        for batch_start in range(0, dataset.shape[0], BATCH_SIZE):\n","            real_images = dataset[batch_start:batch_start+BATCH_SIZE]\n","            d_loss, g_loss = train_step(real_images, LATENT_DIM, generator, discriminator, gan)\n","\n","        print(f'Epoch {epoch+1}/{epochs}, D Loss: {d_loss.numpy()}, G Loss: {g_loss.numpy()}')\n","\n","# Start training\n","train(dataset, EPOCHS)\n"]},{"cell_type":"code","source":["import os\n","print(\"Current Working Directory:\", os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPTzlZNiMva3","executionInfo":{"status":"ok","timestamp":1737960251808,"user_tz":-330,"elapsed":542,"user":{"displayName":"jayanth suresh","userId":"02580612912048283135"}},"outputId":"1378a73d-bc54-41b5-8416-5bdb24e45cd4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Current Working Directory: /content\n"]}]}]}