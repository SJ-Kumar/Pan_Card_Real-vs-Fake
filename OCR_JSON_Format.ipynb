{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCeXvGG-TGQb",
        "outputId": "d1dd26ea-7b3c-4d13-f3d1-3c8bcccabd02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.20.1\n",
            "Collecting imgocr\n",
            "  Downloading imgocr-0.1.4.tar.gz (20.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting loguru (from imgocr)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from imgocr) (4.67.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from imgocr) (2.0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imgocr) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imgocr) (11.1.0)\n",
            "Collecting pyclipper (from imgocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from imgocr) (2.32.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from imgocr) (4.11.0.86)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->imgocr) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->imgocr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->imgocr) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->imgocr) (2025.1.31)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: imgocr\n",
            "  Building wheel for imgocr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgocr: filename=imgocr-0.1.4-py3-none-any.whl size=20892867 sha256=b99576ab7eb86d66af1e231159017bd0b8f3e69e594c034dcc936d9c604bc2b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/07/1b/f1e51cec29c73ccb981866cb2889e60ff19daf4ae2ab9d03b9\n",
            "Successfully built imgocr\n",
            "Installing collected packages: pyclipper, loguru, imgocr\n",
            "Successfully installed imgocr-0.1.4 loguru-0.7.3 pyclipper-1.3.0.post6\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxruntime\n",
        "!pip install imgocr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO3TLWhwTw1m",
        "outputId": "812398bd-3633-4f83-f890-40f41987c03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.0-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJvs4WoTULHF",
        "outputId": "ef28c692-648b-4fc5-aebb-a33931b5bc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/HongKong_Dataset/train-00000-of-00002.parquet\"\n",
        "\n",
        "dataset = load_dataset(\"parquet\", data_files=dataset_path)['train'].select(range(3))\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EybLjSDGURMA",
        "outputId": "6aaa2101-fa29-4f5c-9509-306c3188b15a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['image', 'ocr'],\n",
            "    num_rows: 3\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance\n",
        "from imgocr import ImgOcr\n",
        "import re\n",
        "import json\n",
        "\n",
        "# Initialize ImgOcr\n",
        "m = ImgOcr(use_gpu=False, is_efficiency_mode=True)  # Using efficiency mode\n",
        "\n",
        "def enhance_image(image):\n",
        "    \"\"\"Enhance image to improve OCR accuracy.\"\"\"\n",
        "    # Convert PIL image to OpenCV format\n",
        "    image = np.array(image)\n",
        "\n",
        "    # Increase image contrast using ImageEnhance\n",
        "    pil_image = Image.fromarray(image)\n",
        "    enhancer = ImageEnhance.Contrast(pil_image)\n",
        "    image = enhancer.enhance(2)  # Adjust the factor for better contrast\n",
        "\n",
        "    # Convert back to numpy array\n",
        "    image = np.array(image)\n",
        "\n",
        "    # Sharpen the image using a kernel for better text distinction\n",
        "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])  # Sharpen kernel\n",
        "    image = cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "    # Convert back to PIL image\n",
        "    return Image.fromarray(image)\n",
        "\n",
        "\n",
        "def extract_personal_number(ocr_result):\n",
        "    \"\"\"Extract personal number in the format 'XXXX XXXX XXXX'.\"\"\"\n",
        "    # Combine OCR result text into one string\n",
        "    ocr_text = \" \".join([i['text'] for i in ocr_result])\n",
        "\n",
        "    # Remove any dots and the digit following the dot\n",
        "    ocr_text_cleaned = re.sub(r\"\\.\\d\", \"\", ocr_text)  # Remove dots and digits after them\n",
        "\n",
        "    # Use regular expression to find a 12-digit personal number, handling cases like overflow or dots\n",
        "    match = re.search(r\"(\\d{4})[\\s]?(\\d{4})[\\s]?(\\d{4})\", ocr_text_cleaned)\n",
        "\n",
        "    if match:\n",
        "        # Format the matched personal number in the desired format\n",
        "        personal_number = f\"{match.group(1)} {match.group(2)} {match.group(3)}\"\n",
        "        return personal_number\n",
        "    return None\n",
        "\n",
        "def clean_ocr_response(ocr_result):\n",
        "    \"\"\"Clean the OCR response by removing unwanted labels and getting Chinese name.\"\"\"\n",
        "    # List of unwanted labels or keywords to remove (e.g., Date of Birth, Date of Issue)\n",
        "    unwanted_labels = [\n",
        "        \"Date of Birth\", \"DateofBirth\", \"Date of Issue\", \"DateofIssue\",\n",
        "        \"出生日期\", \"签发日期\", \"Date\", \"Issue\", \"SAMPLE\"\n",
        "    ]\n",
        "\n",
        "    # Filter out text entries containing unwanted labels\n",
        "    cleaned_text = [i['text'] for i in ocr_result if not any(label in i['text'] for label in unwanted_labels)]\n",
        "\n",
        "    # Extract all Chinese text\n",
        "    chinese_text = [text for text in cleaned_text if re.search('[\\u4e00-\\u9fff]', text)]  # Match Chinese characters\n",
        "\n",
        "    # Find the shortest Chinese text assuming it is the name\n",
        "    chinese_full_name = min(chinese_text, key=len, default=None)\n",
        "\n",
        "    return chinese_full_name\n",
        "\n",
        "def extract_document_number(ocr_result):\n",
        "    \"\"\"Extract document number from OCR result based on specified format.\"\"\"\n",
        "    pattern = r\"[A-Za-z][0-9]{6}\\([0-9]\\)$\"\n",
        "\n",
        "    last_text = ocr_result[-1]['text'].strip()\n",
        "\n",
        "    if re.match(pattern, last_text):\n",
        "        return {\"document Number\": last_text}\n",
        "    elif re.match(r\"[A-Za-z][0-9]{6}\", last_text):\n",
        "        return {\"document Number\": last_text}\n",
        "\n",
        "    return {\"document Number\": None}  # Return null if no match found\n",
        "\n",
        "def extract_date_of_birth(ocr_result):\n",
        "    \"\"\"Extract the date of birth in 'dd-mm-yyyy' format from OCR result.\"\"\"\n",
        "    # Combine OCR result text into one string\n",
        "    ocr_text = \" \".join([i['text'] for i in ocr_result])\n",
        "\n",
        "    # Use regular expression to find dates in dd-mm-yyyy format\n",
        "    match = re.search(r\"(\\d{2}-\\d{2}-\\d{4})\", ocr_text)\n",
        "\n",
        "    if match:\n",
        "        # Return the date as 'dateOfBirth' in JSON format\n",
        "        return match.group(1)\n",
        "    return None\n",
        "\n",
        "def extract_gender(ocr_result, date_of_birth):\n",
        "    \"\"\"Extract gender based on the date of birth and the line below it.\"\"\"\n",
        "    ocr_text = \" \".join([i['text'] for i in ocr_result])\n",
        "\n",
        "    # Find the position of the date of birth in the text\n",
        "    position = ocr_text.find(date_of_birth)\n",
        "    if position != -1:\n",
        "        # Extract the next line after the date of birth\n",
        "        following_text = ocr_text[position + len(date_of_birth):].strip()\n",
        "\n",
        "        # Check if the gender indicators are present in the following line\n",
        "        if re.search(r\"男|M\", following_text):\n",
        "            return \"Male\"\n",
        "        elif re.search(r\"女|F\", following_text):\n",
        "            return \"Female\"\n",
        "\n",
        "    # Return None (null) if no gender found on the line below the date of birth\n",
        "    return None\n",
        "\n",
        "def extract_dob_symbol(ocr_result):\n",
        "    \"\"\"Extract dobSymbol of format ***XX (with three asterisks followed by two alphabets).\"\"\"\n",
        "    # Combine OCR result text into one string\n",
        "    ocr_text = \" \".join([i['text'] for i in ocr_result])\n",
        "\n",
        "    # Use regular expression to find a pattern like \"***AZ\"\n",
        "    match = re.search(r\"\\*\\*\\*([A-Za-z]{2})\", ocr_text)\n",
        "\n",
        "    if match:\n",
        "        # Return dobSymbol in JSON format\n",
        "        return {\"dobSymbol\": match.group(0)}\n",
        "    return {\"dobSymbol\": None}  # Return null if no match found\n",
        "\n",
        "def extract_issuing_date(ocr_result):\n",
        "    \"\"\"Extract issuing date in the format (MM-YY) from OCR result.\"\"\"\n",
        "    # Combine OCR result text into one string\n",
        "    ocr_text = \" \".join([i['text'] for i in ocr_result])\n",
        "\n",
        "    # Use regular expression to find dates in (MM-YY) format\n",
        "    match = re.search(r\"\\(\\d{2}-\\d{2}\\)\", ocr_text)\n",
        "\n",
        "    if match:\n",
        "        # Return the issuing date as 'issuing Date' in JSON format\n",
        "        return {\"issuing Date\": match.group(0)[1:-1]}  # Remove parentheses\n",
        "    return {\"issuing Date\": None}  # Return null if no match found\n",
        "\n",
        "\n",
        "def extract_english_name(ocr_result):\n",
        "    \"\"\"Extract English full name, first name, and last name.\"\"\"\n",
        "    # Combine all OCR result text into a single string\n",
        "    ocr_text = \" \".join([i['text'] for i in ocr_result])\n",
        "\n",
        "    # Remove unwanted parts like \"AMPLE SAMPLE\" and \"SAMPLE\" from the OCR text\n",
        "    ocr_text = ocr_text.replace(\"AMPLE SAMPLE\", \"\").replace(\"SAMPLE\", \"\").strip()\n",
        "\n",
        "    # Look for the pattern with a comma, which typically separates the surname and given name\n",
        "    # Assuming that the full name is in the format \"Surname, Givenname\"\n",
        "    match = re.search(r\"([A-Za-z]+),([A-Za-z]+(?:\\s[A-Za-z]+)*)\", ocr_text)\n",
        "\n",
        "    if match:\n",
        "        # Extract surname (before comma) and given name (after comma)\n",
        "        surname = match.group(1)\n",
        "        given_name = match.group(2)\n",
        "\n",
        "        # Clean up spaces, if any, around names\n",
        "        surname = surname.strip()\n",
        "        given_name = given_name.strip()\n",
        "\n",
        "        # Return the JSON with English full name, first name, and last name\n",
        "        return {\n",
        "            \"englishFullName\": f\"{surname},{given_name}\",\n",
        "            \"englishGivenName\": f\"{surname},{given_name}\",\n",
        "            \"firstName\": given_name,\n",
        "            \"englishSurname\": surname\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"englishFullName\": None,\n",
        "        \"englishGivenName\": None,\n",
        "        \"firstName\": None,\n",
        "        \"englishSurname\": None\n",
        "    }\n",
        "\n",
        "def extract_chinese_surname(chinese_full_name):\n",
        "    \"\"\"Extract the Chinese surname from the full name.\"\"\"\n",
        "    if chinese_full_name:\n",
        "        # Return the first character as surname\n",
        "        surname = chinese_full_name[0]\n",
        "        return {\"chineseSurname\": surname}\n",
        "    return {\"chineseSurname\": None}\n",
        "\n",
        "# Load image from drive\n",
        "image_path = \"/content/drive/MyDrive/HongKong_Dataset/new_hkid_front.png\"  # Replace with your image path\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Enhance the image\n",
        "enhanced_image = enhance_image(image)\n",
        "\n",
        "# Perform OCR\n",
        "result = m.ocr(enhanced_image)\n",
        "\n",
        "# Print OCR results\n",
        "print(f\"🔹 OCR Results for {image_path}:\")\n",
        "for i in result:\n",
        "    print(i['text'])\n",
        "\n",
        "# Extract document number from the OCR result\n",
        "document_number_json = extract_document_number(result)\n",
        "\n",
        "# Print the document number JSON response (null if not found)\n",
        "print(\"🔹 Document Number extracted:\")\n",
        "print(document_number_json)\n",
        "\n",
        "# Extract Chinese Full Name\n",
        "chinese_full_name = clean_ocr_response(result)\n",
        "\n",
        "# Return the Chinese Full Name as JSON, ensure Chinese characters are not escaped\n",
        "chinese_given_name_json = json.dumps({\"chineseGivenName\": chinese_full_name if chinese_full_name else None}, ensure_ascii=False)\n",
        "\n",
        "chinese_full_name_json = json.dumps({\"chineseFullName\": chinese_full_name if chinese_full_name else None}, ensure_ascii=False)\n",
        "\n",
        "# Print the Chinese Full Name response\n",
        "print(\"🔹 Chinese Full Name extracted:\")\n",
        "print(chinese_full_name_json)\n",
        "\n",
        "print(\"🔹 Chinese Given Name extracted:\")\n",
        "print(chinese_given_name_json)\n",
        "\n",
        "# Extract personal number from the OCR result\n",
        "personal_number = extract_personal_number(result)\n",
        "\n",
        "# Return the personal number\n",
        "print(\"🔹 Personal Number extracted:\")\n",
        "print(personal_number)\n",
        "\n",
        "# Extract DOB (Date of Birth)\n",
        "dob = extract_date_of_birth(result)\n",
        "\n",
        "# Print the DOB\n",
        "print(\"🔹 Date of Birth extracted:\")\n",
        "print(dob)\n",
        "\n",
        "# Extract gender (assuming next line contains gender info)\n",
        "gender = extract_gender(result, dob)\n",
        "\n",
        "# Print gender\n",
        "print(\"🔹 Gender extracted:\")\n",
        "print(gender)\n",
        "\n",
        "# Extract dobSymbol\n",
        "dob_symbol_json = extract_dob_symbol(result)\n",
        "\n",
        "# Print dobSymbol response\n",
        "print(\"🔹 dobSymbol extracted:\")\n",
        "print(dob_symbol_json)\n",
        "\n",
        "# Extract issuing date\n",
        "issuing_date_json = extract_issuing_date(result)\n",
        "\n",
        "# Print issuing date response\n",
        "print(\"🔹 Issuing Date extracted:\")\n",
        "print(issuing_date_json)\n",
        "\n",
        "# Extract English name components\n",
        "english_name_json = extract_english_name(result)\n",
        "\n",
        "# Print English name JSON response\n",
        "print(\"🔹 English Full Name extracted:\")\n",
        "print(json.dumps(english_name_json, ensure_ascii=False))\n",
        "\n",
        "# Extract Chinese surname (if applicable)\n",
        "chinese_surname_json = extract_chinese_surname(chinese_full_name)\n",
        "\n",
        "# Print Chinese surname JSON response\n",
        "print(\"🔹 Chinese Surname extracted:\")\n",
        "print(json.dumps(chinese_surname_json, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7CM5AfHU1pB",
        "outputId": "e9041082-9c33-419b-f289-b7500bd060a0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 OCR Results for /content/drive/MyDrive/HongKong_Dataset/new_hkid_front.png:\n",
            "香港永久性居民身份證\n",
            "HONG KONG PERMANENTIDENTITY CARD\n",
            "m\n",
            "樂永晴\n",
            "Z683365\n",
            "LoK,wing\n",
            "AMPLE SAMPLE \n",
            "Ching\n",
            "2867.3\n",
            "3057 2532\n",
            "出生日期DateofBirth\n",
            "03-06-1985\n",
            "***AZ\n",
            "签发日期 Date of Issue \n",
            "SAMPLE\n",
            "(06-96)\n",
            "26-11-18\n",
            "Z683365(5)\n",
            "🔹 Document Number extracted:\n",
            "{'document Number': 'Z683365(5)'}\n",
            "🔹 Chinese Full Name extracted:\n",
            "{\"chineseFullName\": \"樂永晴\"}\n",
            "🔹 Chinese Given Name extracted:\n",
            "{\"chineseGivenName\": \"樂永晴\"}\n",
            "🔹 Personal Number extracted:\n",
            "2867 3057 2532\n",
            "🔹 Date of Birth extracted:\n",
            "03-06-1985\n",
            "🔹 Gender extracted:\n",
            "Male\n",
            "🔹 dobSymbol extracted:\n",
            "{'dobSymbol': '***AZ'}\n",
            "🔹 Issuing Date extracted:\n",
            "{'issuing Date': '06-96'}\n",
            "🔹 English Full Name extracted:\n",
            "{\"englishFullName\": \"LoK,wing\", \"englishGivenName\": \"LoK,wing\", \"firstName\": \"wing\", \"englishSurname\": \"LoK\"}\n",
            "🔹 Chinese Surname extracted:\n",
            "{\"chineseSurname\": \"樂\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def generate_final_json(document_number, chinese_full_name, chinese_given_name, english_name, chinese_surname, gender, dob, dob_symbol, issuing_date, personal_number):\n",
        "    \"\"\"Generate the final JSON output in the desired format.\"\"\"\n",
        "    final_output = {\n",
        "        \"documentType\": \"national_identity_card\",\n",
        "        \"issuingCountry\": \"HKG\",\n",
        "        \"extractedOcrData\": {\n",
        "            **extract_document_number(result),\n",
        "            \"chineseFullName\": chinese_full_name,\n",
        "            \"chineseGivenName\": chinese_given_name,\n",
        "            \"englishFullName\": english_name.get(\"englishFullName\"),\n",
        "            \"englishGivenName\": english_name.get(\"englishGivenName\"),\n",
        "            \"firstName\": english_name.get(\"firstName\"),\n",
        "            \"englishSurname\": english_name.get(\"englishSurname\"),\n",
        "            \"chineseSurname\": chinese_surname,\n",
        "            \"gender\": gender,\n",
        "            \"dateofBirth\": dob,\n",
        "            \"dateOfExpiry\": None,  # Always keep null\n",
        "            \"dobSymbol\": dob_symbol.get(\"dobSymbol\"),\n",
        "            \"issuing Date\": issuing_date.get(\"issuing Date\"),\n",
        "            \"personalNumber\": personal_number\n",
        "        }\n",
        "    }\n",
        "    return json.dumps(final_output, ensure_ascii=False, indent=4)\n",
        "\n",
        "final_json = generate_final_json(\n",
        "    document_number=document_number_json,\n",
        "    chinese_full_name=chinese_full_name,\n",
        "    chinese_given_name=chinese_full_name,\n",
        "    english_name=english_name_json,\n",
        "    chinese_surname=chinese_surname_json.get(\"chineseSurname\"),\n",
        "    gender=gender,\n",
        "    dob=dob,\n",
        "    dob_symbol=dob_symbol_json,\n",
        "    issuing_date=issuing_date_json,\n",
        "    personal_number=personal_number\n",
        ")\n",
        "\n",
        "\n",
        "print(final_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDl4GOq7TbaH",
        "outputId": "5e8ed83c-0e70-45ef-a661-2a059aafc24d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"documentType\": \"national_identity_card\",\n",
            "    \"issuingCountry\": \"HKG\",\n",
            "    \"extractedOcrData\": {\n",
            "        \"document Number\": \"Z683365(5)\",\n",
            "        \"chineseFullName\": \"樂永晴\",\n",
            "        \"chineseGivenName\": \"樂永晴\",\n",
            "        \"englishFullName\": \"LoK,wing\",\n",
            "        \"englishGivenName\": \"LoK,wing\",\n",
            "        \"firstName\": \"wing\",\n",
            "        \"englishSurname\": \"LoK\",\n",
            "        \"chineseSurname\": \"樂\",\n",
            "        \"gender\": \"Male\",\n",
            "        \"dateofBirth\": \"03-06-1985\",\n",
            "        \"dateOfExpiry\": null,\n",
            "        \"dobSymbol\": \"***AZ\",\n",
            "        \"issuing Date\": \"06-96\",\n",
            "        \"personalNumber\": \"2867 3057 2532\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}